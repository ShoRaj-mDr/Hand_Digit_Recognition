{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand Digit Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "from skimage import io, transform\n",
    "from PIL import Image as im\n",
    "import cv2, time, sys, os\n",
    "\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing import image as kerasimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the images with dimension (1, 64, 64, 3) using cv2 \n",
    "# returns images and label as nparray\n",
    "def load_data(folder):\n",
    "    images = [] \n",
    "    labels = [] \n",
    "    # Obtain all images and their labels from the directory\n",
    "    for filename in os.listdir(folder):\n",
    "        read_img = cv2.imread(os.path.join(folder, filename))\n",
    "        if read_img is not None:\n",
    "            # Only taking left hand images\n",
    "            if filename[-5] == 'L':\n",
    "                # Resizing 128x128x3 pixel original image into 64x64x3 \n",
    "                read_img = cv2.resize(read_img, (64,64))\n",
    "                ## img_binary = cv2.threshold(read_img, 70, 255, cv2.THRESH_BINARY)[1]\n",
    "                ## images.append(img_binary)\n",
    "                images.append(read_img)\n",
    "                labels.append(filename[-6]) # Get the label\n",
    "    images =  np.asarray(images)\n",
    "    labels = np.asarray(labels)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a single image using imshow\n",
    "def display_image(img):\n",
    "    plt.figure()\n",
    "    plt.imshow(img) \n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief dataset description\n",
    "Dataset contains total of 21,600 images <br>\n",
    "- Training set: 18000 images <br>\n",
    "- Testing set: 3600 images <br>\n",
    "\n",
    "### Label\n",
    "Labels are in two last characters of filename <br>\n",
    "- L/R indicates left/right hand <br>\n",
    "- 0,1,2,3,4,5 indicates number of fingers <br>\n",
    "- With 0-5 digits and L/R hand, there are 12 total classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the path of the image directory for test and train set\n",
    "# Obtain dataset with their labels\n",
    "X_train, Y_train = load_data('./data/train/')\n",
    "X_test, Y_test = load_data('./data/test/')\n",
    "\n",
    "# Show the shape of training and testing set along with their label\n",
    "print(\"X training dataset: \", X_train.shape)\n",
    "print(\"Y training dataset: \", Y_train.shape)\n",
    "print(\"X testing dataset: \", X_test.shape)\n",
    "print(\"Y testing dataset: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display image from training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying one random training image with its label\n",
    "print('Label: ', Y_train[552])\n",
    "display_image(X_train[552])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of classes. 0-5 finger digits\n",
    "list_of_classes = ['0', '1', '2', '3', '4', '5']\n",
    "num_classes = len(list_of_classes)\n",
    "\n",
    "# Display images of the training dataset with their labels\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15,10))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X_train[i], cmap='gray')\n",
    "    ax.set_title(f\"Label: {Y_train[i]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels from just an integer into a categorical vector with 1 \n",
    "Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
    "Y_test  = np_utils.to_categorical(Y_test, num_classes)\n",
    "\n",
    "# Convert all datatype into float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalize the images dividing by 255\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ceating a simple CNN using Keras\n",
    "def define_model(train_shape, num_of_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    # 3x3 convolution layer with 2x2 stride and 32 filters\n",
    "    model.add(Conv2D(32, (3, 3), strides = (2,2), padding='same',\n",
    "                    input_shape = train_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # 3x3 convolution layer with 1x1 stride and 64 filters\n",
    "    model.add(Conv2D(64, (3, 3), strides = (1,1)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # 2x2 Max-pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # Faltten into one-dimensional vector and two fully connected dense layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_of_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CNN model and show its summary\n",
    "model_1 = define_model(X_train.shape[1:], num_classes)\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0005, decay=1e-6)\n",
    "\n",
    "# Train the model with categroical_crossentropy loss function and RMSprop optimizer\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# fit the model with 5 epochs\n",
    "history = model_1.fit(X_train, Y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=5,\n",
    "            validation_data=(X_test, Y_test),\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_1.save('model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting accuracy & loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracy of model\n",
    "def plot_accuracy(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='lower right')\n",
    "    plt.show()\n",
    "#     plt.savefig('Accuracy.png')\n",
    "\n",
    "# plot the loss of model\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    plt.show()\n",
    "#     plt.savefig('Loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(history)\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = models.load_model('model_1.h5')\n",
    "list_of_classes = ['0', '1', '2', '3', '4', '5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_1.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(Y_test, axis=1)     \n",
    "y_pred = np.argmax(prediction, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=list_of_classes)\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15,10))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X_test[i], cmap='gray')\n",
    "    ax.set_title(f\"True Label:{list_of_classes[np.argmax(Y_test[i])]}\\n Predicted Label:{list_of_classes[np.argmax(prediction[i])]}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagen = ImageDataGenerator(\n",
    "#         rotation_range=20,\n",
    "#         zoom_range=0.2,\n",
    "#         width_shift_range=0.1,\n",
    "#         height_shift_range=0.1,\n",
    "#         shear_range=0.12, \n",
    "#         rescale=1./255)\n",
    "\n",
    "# # test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# training_set = datagen.flow(X_train, Y_train)\n",
    "# # validation_set = datagen.flow(X_test, Y_test)\n",
    "\n",
    "# # history = model_1.fit(training_set,\n",
    "# ##                       steps_per_epoch=len(training_set),\n",
    "# #                       epochs = 10,\n",
    "# #                       validation_data=validation_set,\n",
    "# ##                       validation_steps = len(validation_set),\n",
    "# #                       shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Real-time Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 = models.load_model('model_1.h5')\n",
    "# list_of_classes = ['0', '1', '2', '3', '4', '5']\n",
    "\n",
    "# camera = cv2.VideoCapture(0)\n",
    "\n",
    "# fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "    \n",
    "# while 1:\n",
    "#     ret, frame = camera.read()\n",
    "#     frame = cv2.flip(frame, 1)\n",
    "    \n",
    "#     top, right, bottom, left = 75, 350, 300, 590\n",
    "#     roi = frame[top:bottom, right:left]\n",
    "#     roi = cv2.flip(roi,1)\n",
    "    \n",
    "#     roi = fgbg.apply(roi)\n",
    "    \n",
    "#     # gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "#     gray = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "#     gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "#     cv2.imshow('roi', gray)\n",
    "\n",
    "#     myimage = np.asarray(gray)\n",
    "#     myimage = cv2.resize(myimage, (64, 64))\n",
    "#     myimage = kerasimage.img_to_array(myimage, dtype='float32')\n",
    "#     # myimage = cv2.threshold(myimage, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "#     myimage /= 255 \n",
    "#     myimage = np.expand_dims(myimage, axis=0)\n",
    "#     pred_list = model_1.predict(myimage)\n",
    "#     # print(pred_list)\n",
    "#     result = list_of_classes[np.argmax(pred_list)]\n",
    "    \n",
    "#     cv2.rectangle(frame, (left, top), (right, bottom), (0,255,0), 2)\n",
    "#     cv2.putText(frame, str(result),(0,130),cv2.FONT_HERSHEY_SIMPLEX,5,(0,0,255),2)\n",
    "#     cv2.imshow('Frame', frame)\n",
    "    \n",
    "#     # Press 'q' or 'esc' key to exit\n",
    "#     key = cv2.waitKey(1) & 0xFF\n",
    "#     if key == ord('q'):\n",
    "#         break\n",
    "        \n",
    "#     if cv2.waitKey(1) == 27:\n",
    "#         break \n",
    "        \n",
    "# camera.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
